{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MB63oUQ3aDTF6dnT_o9naCyxIC4gDeXS",
      "authorship_tag": "ABX9TyNMoVhPAEHXl/eK7R/was1Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayush2803/GlobalHawks/blob/main/YOLO_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FkjNOI_uAiDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gwi59Qc3pTi"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import datetime\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten, Input\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from math import sin, cos, radians"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 224\n",
        "CHANNELS = 3"
      ],
      "metadata": {
        "id": "j9_BsN-w46vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset to memory:\n",
        "images_folder = r'/content/drive/MyDrive/Dataset (1)'\n",
        "labels = []\n",
        "images = []\n",
        "\n",
        "def resize(img, target):\n",
        "    \"\"\" Resize an image \"\"\"\n",
        "    resized = cv2.resize(img, (target, target),\n",
        "                         interpolation = cv2.INTER_AREA).astype(np.float32)\n",
        "    return resized.reshape((-1))\n",
        "\n",
        "for folder in os.listdir(images_folder):\n",
        "    if folder in ('WithTarget','WithoutTarget'):\n",
        "        for filename in os.listdir(os.path.join(images_folder,folder)):\n",
        "            labels.append(folder)\n",
        "            img = cv2.imread(os.path.join(images_folder,folder,filename))\n",
        "            images.append(resize(img, IMAGE_SIZE))\n",
        "            \n",
        "images = np.array(images)\n",
        "labels = pd.get_dummies(labels).to_numpy()"
      ],
      "metadata": {
        "id": "bEatlagp3uUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data partitioning\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    images.reshape(-1,IMAGE_SIZE,IMAGE_SIZE,CHANNELS),\n",
        "    labels, train_size=0.7, stratify=labels, random_state=42)"
      ],
      "metadata": {
        "id": "1IkbtYo04-eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(df):\n",
        "    df = np.array(df)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    indices = np.random.choice(np.arange(len(df)),\n",
        "                               9, replace=False)\n",
        "    images = df[indices]\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(cv2.cvtColor(images[i].reshape((224,224,3))\n",
        "                                .astype('uint8'), cv2.COLOR_BGR2RGB))\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "aiwhExAY5Awn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_images(x_train[y_train[:,0]==1])"
      ],
      "metadata": {
        "id": "tgTn7HUT5C2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_images(x_train[y_train[:,1]==1])"
      ],
      "metadata": {
        "id": "M_r-LI-o5EvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_noise(img):\n",
        "    '''Add random noise to an image'''\n",
        "    VARIABILITY = 50\n",
        "    deviation = VARIABILITY*np.random.rand()\n",
        "    noise = np.random.normal(0, deviation, img.shape)\n",
        "    img += noise\n",
        "    np.clip(img, 0., 255.)\n",
        "    return img\n",
        "\n",
        "# Generating augmentations\n",
        "trdata = ImageDataGenerator(rescale=1./255, rotation_range=40,\n",
        "                            width_shift_range=0.2, height_shift_range=0.2,\n",
        "                            horizontal_flip=True, channel_shift_range=50,\n",
        "                            preprocessing_function = add_noise)\n",
        "traindata = trdata.flow(x_train, y_train,batch_size=32)\n",
        "\n",
        "tsdata = ImageDataGenerator(rescale=1./255, rotation_range=40,\n",
        "                            width_shift_range=0.2, height_shift_range=0.2,\n",
        "                            horizontal_flip=True, channel_shift_range=50,\n",
        "                            preprocessing_function = add_noise)\n",
        "testdata = tsdata.flow(x_test, y_test,batch_size=32)\n",
        "\n",
        "# Load VGG19 architecture as transfer learning model\n",
        "vgg = VGG19(weights='imagenet', include_top=False,\n",
        "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
        "vgg.trainable = False\n",
        "flatten = Flatten()(vgg.output)\n",
        "d1 = Dense(2, activation=\"softmax\")(flatten)\n",
        "model = Model(inputs=vgg.input, outputs=d1)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "NsrkJ1Hq5ICk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exponential_decay(lr, s):\n",
        "    def exponential_decay_fn(epoch):\n",
        "        return lr * 0.1\n",
        "    return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(0.01, 5) # when i run it for 50 epochs\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)"
      ],
      "metadata": {
        "id": "DLc-1ZGyEJMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss=categorical_crossentropy, metrics=['accuracy'])\n",
        "early = EarlyStopping(monitor='val_accuracy',\n",
        "                      min_delta=0, verbose=1, patience=5, mode='auto')\n",
        "hist = model.fit(traindata, steps_per_epoch=10, \n",
        "                 verbose=2, validation_data=testdata, validation_steps=5,\n",
        "                 epochs=30, callbacks=lr_scheduler, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf05ubqC5NfO",
        "outputId": "839a4021-428c-430f-f624-47fb64b5e2f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "10/10 - 11s - loss: 1.0293 - accuracy: 0.7930 - val_loss: 0.7037 - val_accuracy: 0.8750 - lr: 0.0010 - 11s/epoch - 1s/step\n",
            "Epoch 2/30\n",
            "10/10 - 16s - loss: 0.4221 - accuracy: 0.8662 - val_loss: 0.4034 - val_accuracy: 0.9000 - lr: 0.0010 - 16s/epoch - 2s/step\n",
            "Epoch 3/30\n",
            "10/10 - 10s - loss: 0.2723 - accuracy: 0.9013 - val_loss: 0.4542 - val_accuracy: 0.7625 - lr: 0.0010 - 10s/epoch - 970ms/step\n",
            "Epoch 4/30\n",
            "10/10 - 10s - loss: 0.3310 - accuracy: 0.8822 - val_loss: 0.3416 - val_accuracy: 0.8500 - lr: 0.0010 - 10s/epoch - 980ms/step\n",
            "Epoch 5/30\n",
            "10/10 - 10s - loss: 0.3479 - accuracy: 0.8981 - val_loss: 0.3417 - val_accuracy: 0.8562 - lr: 0.0010 - 10s/epoch - 975ms/step\n",
            "Epoch 6/30\n",
            "10/10 - 10s - loss: 0.2724 - accuracy: 0.9076 - val_loss: 0.2948 - val_accuracy: 0.8687 - lr: 0.0010 - 10s/epoch - 973ms/step\n",
            "Epoch 7/30\n",
            "10/10 - 10s - loss: 0.4100 - accuracy: 0.8312 - val_loss: 0.4646 - val_accuracy: 0.7750 - lr: 0.0010 - 10s/epoch - 977ms/step\n",
            "Epoch 8/30\n",
            "10/10 - 12s - loss: 0.3806 - accuracy: 0.8625 - val_loss: 0.2903 - val_accuracy: 0.9000 - lr: 0.0010 - 12s/epoch - 1s/step\n",
            "Epoch 9/30\n",
            "10/10 - 20s - loss: 0.3288 - accuracy: 0.8758 - val_loss: 0.3769 - val_accuracy: 0.8188 - lr: 0.0010 - 20s/epoch - 2s/step\n",
            "Epoch 10/30\n",
            "10/10 - 10s - loss: 0.3703 - accuracy: 0.8758 - val_loss: 0.2975 - val_accuracy: 0.8938 - lr: 0.0010 - 10s/epoch - 981ms/step\n",
            "Epoch 11/30\n",
            "10/10 - 12s - loss: 0.2993 - accuracy: 0.8822 - val_loss: 0.3786 - val_accuracy: 0.8750 - lr: 0.0010 - 12s/epoch - 1s/step\n",
            "Epoch 12/30\n",
            "10/10 - 10s - loss: 0.3380 - accuracy: 0.8885 - val_loss: 0.4323 - val_accuracy: 0.8813 - lr: 0.0010 - 10s/epoch - 976ms/step\n",
            "Epoch 13/30\n",
            "10/10 - 10s - loss: 0.4326 - accuracy: 0.8631 - val_loss: 0.6947 - val_accuracy: 0.8625 - lr: 0.0010 - 10s/epoch - 974ms/step\n",
            "Epoch 14/30\n",
            "10/10 - 10s - loss: 0.4193 - accuracy: 0.8344 - val_loss: 0.4851 - val_accuracy: 0.8875 - lr: 0.0010 - 10s/epoch - 976ms/step\n",
            "Epoch 15/30\n",
            "10/10 - 10s - loss: 0.4159 - accuracy: 0.8471 - val_loss: 0.5608 - val_accuracy: 0.8687 - lr: 0.0010 - 10s/epoch - 973ms/step\n",
            "Epoch 16/30\n",
            "10/10 - 11s - loss: 0.4697 - accuracy: 0.8376 - val_loss: 0.6899 - val_accuracy: 0.8625 - lr: 0.0010 - 11s/epoch - 1s/step\n",
            "Epoch 17/30\n",
            "10/10 - 10s - loss: 0.5304 - accuracy: 0.8185 - val_loss: 0.5368 - val_accuracy: 0.8687 - lr: 0.0010 - 10s/epoch - 980ms/step\n",
            "Epoch 18/30\n",
            "10/10 - 10s - loss: 0.5807 - accuracy: 0.8439 - val_loss: 0.3442 - val_accuracy: 0.9125 - lr: 0.0010 - 10s/epoch - 978ms/step\n",
            "Epoch 19/30\n",
            "10/10 - 10s - loss: 0.4260 - accuracy: 0.8662 - val_loss: 0.2816 - val_accuracy: 0.9000 - lr: 0.0010 - 10s/epoch - 984ms/step\n",
            "Epoch 20/30\n",
            "10/10 - 10s - loss: 0.3723 - accuracy: 0.8567 - val_loss: 0.3183 - val_accuracy: 0.8750 - lr: 0.0010 - 10s/epoch - 979ms/step\n",
            "Epoch 21/30\n",
            "10/10 - 11s - loss: 0.3037 - accuracy: 0.8949 - val_loss: 0.3656 - val_accuracy: 0.8438 - lr: 0.0010 - 11s/epoch - 1s/step\n",
            "Epoch 22/30\n",
            "10/10 - 10s - loss: 0.3259 - accuracy: 0.8917 - val_loss: 0.3430 - val_accuracy: 0.8500 - lr: 0.0010 - 10s/epoch - 978ms/step\n",
            "Epoch 23/30\n",
            "10/10 - 10s - loss: 0.2985 - accuracy: 0.8790 - val_loss: 0.2986 - val_accuracy: 0.8687 - lr: 0.0010 - 10s/epoch - 989ms/step\n",
            "Epoch 24/30\n",
            "10/10 - 10s - loss: 0.3205 - accuracy: 0.8719 - val_loss: 0.3483 - val_accuracy: 0.8500 - lr: 0.0010 - 10s/epoch - 990ms/step\n",
            "Epoch 25/30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "epochs_range = range(1, len(hist.epoch) + 1)\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Train Set')\n",
        "plt.plot(epochs_range, val_acc, label='Val Set')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Train Set')\n",
        "plt.plot(epochs_range, val_loss, label='Val Set')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Model Loss')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ARsLbgEZJYK9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}